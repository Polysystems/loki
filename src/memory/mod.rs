use anyhow::Result;
use parking_lot::RwLock;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tracing::{info, warn};
use wide::f32x8;

pub mod cache;
pub mod embeddings;
pub mod layers;
pub mod persistence;
pub mod simd_cache;
pub mod prefetch_engine;
pub mod cache_controller;
pub mod fractal;
pub mod fractal_activation;
pub mod fractal_interface;
pub mod pattern_learning;
pub mod associations;

pub use cache::SimdCache;
pub use embeddings::EmbeddingStore;
pub use fractal_interface::{FractalMemoryInterface, FractalDomainInfo, EmergenceEventInfo, ScaleInfo};
pub use layers::{MemoryLayer, LayerType};
pub use persistence::PersistentMemory;
pub use simd_cache::{
    SimdSmartCache,
    SimdCacheConfig,
    CacheKey,
    CachedNeuron,
    CacheSizeStats,
    AlignedVec,
};
pub use prefetch_engine::{
    NeuralPrefetchEngine,
    PrefetchStats,
    PrefetchRequest,
    PrefetchScheduler,
    PathwayPattern,
};
pub use cache_controller::{
    AdaptiveCacheController,
    CacheLevelConfig,
    CacheMetrics,
    CacheControllerStats,
    SizingStrategy,
};
pub use associations::{
    MemoryAssociationManager,
    AssociationConfig,
    AssociationCluster,
    AssociationLink,
    AssociationType,
    TopicCluster,
    ContactGraph,
    ContactNode,
    EmailAssociationCluster,
    CognitivePatternLink,
    AssociationAnalytics,
};
pub use fractal::{FractalNodeId, MemoryContent};
pub use fractal_activation::{
    FractalMemoryActivator, FractalActivationConfig, PatternType, LearnedPattern,
    FractalActivationStats, ActivationEvent, ConsciousnessSnapshot, EmergenceEventRecord,
};
pub use pattern_learning::{
    PatternLearningSystem, PatternLearningConfig, PatternLearningAnalytics,
    PatternValidationResult, PatternCluster, PatternEvolution, EvolutionType,
    LearningEvent, PatternEvent,
};

// MemoryId is defined in this module

/// Cognitive memory system with layered architecture
#[derive(Debug)]
pub struct CognitiveMemory {
    /// Short-term memory (working memory)
    short_term: Arc<RwLock<MemoryLayer>>,

    /// Long-term memory layers
    long_term_layers: Vec<Arc<RwLock<MemoryLayer>>>,

    /// Embedding store for semantic search
    embeddings: Arc<EmbeddingStore>,

    /// SIMD-optimized cache
    cache: Arc<SimdCache>,

    /// Persistent storage
    persistence: Arc<PersistentMemory>,

    /// Association manager for intelligent linking
    association_manager: Arc<MemoryAssociationManager>,
    
    /// Fractal memory interface (optional)
    fractal_interface: Option<Arc<FractalMemoryInterface>>,
    
    /// Track last consolidation time
    last_consolidation_time: Option<chrono::DateTime<chrono::Utc>>,

    /// Configuration
    config: MemoryConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryConfig {
    pub short_term_capacity: usize,
    pub long_term_layers: usize,
    pub layer_capacity: usize,
    pub embedding_dim: usize,
    pub cache_size_mb: usize,
    pub persistence_path: PathBuf,
    pub consolidation_threshold: f32,
    pub decay_rate: f32,

    // Additional fields for backward compatibility
    pub max_memory_mb: Option<usize>,      // Alternative to cache_size_mb
    pub context_window: Option<usize>,     // Context window size
    pub enable_persistence: bool,          // Whether to enable persistence
    pub max_age_days: Option<u32>,         // Maximum age for memories
    pub embedding_dimension: Option<usize>, // Alternative to embedding_dim
}

impl Default for MemoryConfig {
    fn default() -> Self {
        Self {
            short_term_capacity: 100,
            long_term_layers: 5,
            layer_capacity: 1000,
            embedding_dim: 384, // MiniLM dimension
            cache_size_mb: 512,
            persistence_path: dirs::data_dir()
                .unwrap_or_else(|| PathBuf::from("."))
                .join(".loki")
                .join("memory"),
            consolidation_threshold: 0.8,
            decay_rate: 0.95,

            // Additional fields with defaults
            max_memory_mb: None,
            context_window: None,
            enable_persistence: true,
            max_age_days: None,
            embedding_dimension: None,
        }
    }
}

impl CognitiveMemory {
    /// Create a minimal production-ready instance for testing/initialization
    /// This creates a fully functional memory system with temporary storage
    pub fn placeholder() -> Self {
        // Create minimal configuration with temp directory
        let temp_dir = std::env::temp_dir().join(format!("loki_memory_{}", uuid::Uuid::new_v4()));
        let config = MemoryConfig {
            persistence_path: temp_dir.clone(),
            cache_size_mb: 256, // Reduced cache for minimal instance
            short_term_capacity: 50,
            long_term_layers: 3,
            layer_capacity: 500,
            ..Default::default()
        };
        
        // Create production-ready components with minimal resources
        let rt = tokio::runtime::Runtime::new().expect("Failed to create runtime");
        
        Self {
            short_term: Arc::new(RwLock::new(MemoryLayer::new(LayerType::ShortTerm, config.short_term_capacity))),
            long_term_layers: (0..config.long_term_layers)
                .map(|i| Arc::new(RwLock::new(MemoryLayer::new(
                    LayerType::LongTerm(i),
                    config.layer_capacity * (i + 1),
                ))))
                .collect(),
            embeddings: Arc::new(rt.block_on(EmbeddingStore::new(
                config.embedding_dim,
                &temp_dir
            )).unwrap_or_else(|_| rt.block_on(EmbeddingStore::new(
                config.embedding_dim,
                &std::path::Path::new("/tmp")
            )).expect("Failed to create embedding store"))),
            cache: Arc::new(SimdCache::new(config.cache_size_mb * 1024 * 1024)),
            persistence: Arc::new(
                rt.block_on(PersistentMemory::new(&temp_dir))
                    .unwrap_or_else(|_| rt.block_on(PersistentMemory::new(
                        &std::path::Path::new("/tmp").join(format!("loki_persist_{}", uuid::Uuid::new_v4()))
                    )).expect("Failed to create persistence"))
            ),
            association_manager: Arc::new(
                rt.block_on(MemoryAssociationManager::new(
                    crate::memory::associations::AssociationConfig::default()
                )).expect("Failed to create association manager")
            ),
            fractal_interface: None, // Optional component
            last_consolidation_time: None,
            config,
        }
    }
    
    /// Create a new cognitive memory system
    pub async fn new(config: MemoryConfig) -> Result<Self> {
        info!("Initializing cognitive memory system");

        // Handle compatibility fields
        let cache_size = config.max_memory_mb.unwrap_or(config.cache_size_mb);
        let embedding_dim = config.embedding_dimension.unwrap_or(config.embedding_dim);

        // Create persistence layer with graceful fallback
        let persistence = match config.enable_persistence {
            true => {
                match PersistentMemory::new(&config.persistence_path).await {
                    Ok(persistence) => {
                        info!("‚úÖ Persistent memory initialized successfully");
                        Arc::new(persistence)
                    }
                    Err(e) => {
                        warn!("‚ö†Ô∏è  Failed to initialize persistent memory: {}. Running in memory-only mode.", e);
                        // Create a fallback in-memory persistence layer
                        Arc::new(Self::create_fallback_persistence().await?)
                    }
                }
            }
            false => {
                info!("üìÑ Persistent memory disabled - running in memory-only mode");
                Arc::new(Self::create_fallback_persistence().await?)
            }
        };

        // Create embedding store with graceful fallback
        let embeddings = match EmbeddingStore::new(embedding_dim, &config.persistence_path).await {
            Ok(embeddings) => {
                info!("‚úÖ Embedding store initialized successfully");
                Arc::new(embeddings)
            }
            Err(e) => {
                warn!("‚ö†Ô∏è  Failed to initialize embedding store: {}. Using minimal embedding system.", e);
                Arc::new(Self::create_fallback_embeddings(embedding_dim).await?)
            }
        };

        // Create SIMD cache
        let cache = Arc::new(SimdCache::new(cache_size * 1024 * 1024));

        // Create association manager
        let associationconfig = AssociationConfig::default();
        let association_manager = Arc::new(MemoryAssociationManager::new(associationconfig).await?);

        // Create memory layers
        let short_term = Arc::new(RwLock::new(
            MemoryLayer::new(LayerType::ShortTerm, config.short_term_capacity)
        ));

        let mut long_term_layers = Vec::new();
        for i in 0..config.long_term_layers {
            long_term_layers.push(Arc::new(RwLock::new(
                MemoryLayer::new(
                    LayerType::LongTerm(i),
                    config.layer_capacity * (i + 1), // Increasing capacity per layer
                )
            )));
        }

        // Initialize fractal memory interface (optional, non-blocking)
        let fractal_interface = match FractalMemoryInterface::new().await {
            Ok(interface) => {
                info!("‚úÖ Fractal memory interface initialized");
                Some(Arc::new(interface))
            }
            Err(e) => {
                warn!("‚ö†Ô∏è  Failed to initialize fractal memory interface: {}", e);
                None
            }
        };

        // Load persisted memories
        let mut memory = Self {
            short_term,
            long_term_layers,
            embeddings,
            cache,
            persistence,
            association_manager,
            fractal_interface,
            last_consolidation_time: None,
            config,
        };

        memory.load_from_persistence().await?;

        Ok(memory)
    }

    /// Create a new cognitive memory system with isolated database for testing
    #[cfg(test)]
    pub async fn new_for_test() -> Result<Self> {
        use tempfile::TempDir;
        use anyhow::Context;

        // Create isolated temporary directory for this test
        let temp_dir = TempDir::new().context("Failed to create temporary directory for test")?;
        let test_path = temp_dir.path().to_path_buf();

        let mut config = MemoryConfig::default();
        config.persistence_path = test_path.join("test_memory");
        config.cache_size_mb = 64; // Smaller cache for tests
        config.short_term_capacity = 10;
        config.long_term_layers = 2;
        config.layer_capacity = 20;

        // Keep temp_dir alive by storing it in the config (hack to prevent cleanup)
        // In a real implementation, you'd manage this more elegantly
        let memory = Self::new(config).await?;

        // Store temp_dir reference to prevent cleanup during test
        std::mem::forget(temp_dir);

        Ok(memory)
    }

    /// Create a minimal cognitive memory system for bootstrap initialization
    pub async fn new_minimal() -> Result<Arc<Self>> {
        info!("Initializing minimal cognitive memory system");

        let mut config = MemoryConfig::default();
        config.cache_size_mb = 128; // Smaller cache for minimal setup
        config.short_term_capacity = 50;
        config.long_term_layers = 3;
        config.layer_capacity = 100;
        config.enable_persistence = false; // Disable persistence for minimal setup

        let memory = Self::new(config).await?;
        Ok(Arc::new(memory))
    }

    /// Create a new cognitive memory system with in-memory only storage
    pub async fn new_in_memory() -> Result<Self> {
        info!("Initializing in-memory cognitive memory system");

        let mut config = MemoryConfig::default();
        config.cache_size_mb = 256; // Reasonable cache for in-memory
        config.short_term_capacity = 100;
        config.long_term_layers = 3;
        config.layer_capacity = 500;
        config.enable_persistence = false; // No persistence for in-memory

        let memory = Self::new(config).await?;
        Ok(memory)
    }

    /// Store a memory with context and automatic association creation
    pub async fn store(
        &self,
        content: String,
        context: Vec<String>,
        mut metadata: MemoryMetadata,
    ) -> Result<MemoryId> {
        let memory_id = MemoryId::new();

        // Create associations automatically before storing
        let associated_ids = self.association_manager
            .create_associations(memory_id.clone(), &content, &metadata, self)
            .await
            .unwrap_or_else(|e| {
                warn!("Failed to create associations: {}", e);
                Vec::new()
            });

        // Update metadata with associations
        metadata.associations.extend(associated_ids);

        // Create memory item
        let item = MemoryItem {
            id: memory_id.clone(),
            content: content.clone(),
            context,
            metadata,
            timestamp: chrono::Utc::now(),
            access_count: 0,
            relevance_score: 1.0,
        };

        // Store in short-term memory
        {
            let mut stm = self.short_term.write();
            stm.add(item.clone())?;
        }

        // Generate embedding
        self.embeddings.add(&memory_id, &content).await?;

        // Update cache with SIMD optimization
        self.cache.put(&memory_id, &item)?;

        // Trigger consolidation if needed
        self.maybe_consolidate().await?;

        info!("üíæ Stored memory {} with {} associations", memory_id, item.metadata.associations.len());

        Ok(memory_id)
    }

    /// Retrieve memories by similarity
    pub async fn retrieve_similar(
        &self,
        query: &str,
        limit: usize,
    ) -> Result<Vec<MemoryItem>> {
        // Check cache first
        if let Some(cached) = self.cache.get_similar(query, limit) {
            return Ok(cached);
        }

        // Search embeddings - now returns (MemoryId, similarity_score) tuples
        let similar_results = self.embeddings.search(query, limit * 2).await?;

        // Collect memories from all layers
        let mut memories = Vec::new();

        for (id, similarity_score) in similar_results {
            // Check short-term
            {
                let stm = self.short_term.read();
                if let Some(item) = stm.get(&id) {
                    let mut cloned_item = item.clone();
                    // Boost relevance score with similarity
                    cloned_item.relevance_score = (cloned_item.relevance_score + similarity_score) / 2.0;
                    memories.push(cloned_item);
                    continue;
                }
            }

            // Check long-term layers
            for layer in &self.long_term_layers {
                let ltm = layer.read();
                if let Some(item) = ltm.get(&id) {
                    let mut cloned_item = item.clone();
                    // Boost relevance score with similarity
                    cloned_item.relevance_score = (cloned_item.relevance_score + similarity_score) / 2.0;
                    memories.push(cloned_item);
                    break;
                }
            }
        }

        // Sort by combined relevance score
        memories.sort_by(|a, b| {
            b.relevance_score
                .partial_cmp(&a.relevance_score)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        memories.truncate(limit);

        // Cache results
        self.cache.put_similar_results(query, &memories)?;

        Ok(memories)
    }

    /// Consolidate memories from short-term to long-term
    async fn maybe_consolidate(&self) -> Result<()> {
        let should_consolidate = {
            let stm = self.short_term.read();
            stm.utilization() > self.config.consolidation_threshold
        };

        if !should_consolidate {
            return Ok(());
        }

        info!("Consolidating memories");

        // Get memories to consolidate
        let to_consolidate = {
            let mut stm = self.short_term.write();
            stm.extract_least_relevant(self.config.short_term_capacity / 2)?
        };

        // Move to appropriate long-term layer
        for item in to_consolidate {
            let layer_idx = self.select_layer(&item);
            if let Some(layer) = self.long_term_layers.get(layer_idx) {
                let mut ltm = layer.write();
                ltm.add(item)?;
            }
        }

        // Persist changes
        self.persist_all().await?;

        Ok(())
    }

    /// Select appropriate layer for a memory
    fn select_layer(&self, item: &MemoryItem) -> usize {
        // Simple heuristic: more accessed/relevant memories go to lower layers
        let score = item.relevance_score * (item.access_count as f32).log2().max(1.0);
        let layer = ((1.0 - score) * self.config.long_term_layers as f32) as usize;
        layer.min(self.config.long_term_layers - 1)
    }

    /// Load memories from persistence
    async fn load_from_persistence(&mut self) -> Result<()> {
        if !self.config.enable_persistence {
            return Ok(());
        }

        let memories = self.persistence.load_all().await?;

        for item in memories {
            // Reconstruct embeddings
            self.embeddings.add(&item.id, &item.content).await?;

            // Place in appropriate layer
            if item.timestamp > chrono::Utc::now() - chrono::Duration::hours(24) {
                let mut stm = self.short_term.write();
                stm.add(item)?;
            } else {
                let layer_idx = self.select_layer(&item);
                if let Some(layer) = self.long_term_layers.get(layer_idx) {
                    let mut ltm = layer.write();
                    ltm.add(item)?;
                }
            }
        }

        Ok(())
    }

    /// Persist all memories
    async fn persist_all(&self) -> Result<()> {
        if !self.config.enable_persistence {
            return Ok(());
        }

        let mut all_memories = Vec::new();

        // Collect from short-term
        {
            let stm = self.short_term.read();
            all_memories.extend(stm.all());
        }

        // Collect from long-term
        for layer in &self.long_term_layers {
            let ltm = layer.read();
            all_memories.extend(ltm.all());
        }

        self.persistence.save_all(&all_memories).await?;

        Ok(())
    }

    /// Apply decay to relevance scores
    pub async fn apply_decay(&self) -> Result<()> {
        {
            let mut stm = self.short_term.write();
            stm.apply_decay(self.config.decay_rate);
        }

        for layer in &self.long_term_layers {
            let mut ltm = layer.write();
            ltm.apply_decay(self.config.decay_rate);
        }

        Ok(())
    }

    /// Create a fallback in-memory persistence layer
    async fn create_fallback_persistence() -> Result<PersistentMemory> {
        // Create a temporary in-memory-only persistence layer
        // This will work but won't actually persist data
        use tempfile::TempDir;

        let temp_dir = TempDir::new()?;
        let temp_path = temp_dir.path().to_path_buf();
        std::mem::forget(temp_dir); // Prevent cleanup during fallback operation

        // This will create a working RocksDB instance in a temp directory
        // When the process ends, the data will be lost (which is fine for fallback)
        PersistentMemory::new(&temp_path).await
    }

    /// Create a fallback in-memory embedding store
    async fn create_fallback_embeddings(embedding_dim: usize) -> Result<EmbeddingStore> {
        // Create an embedding store in a temporary location
        use tempfile::TempDir;

        let temp_dir = TempDir::new()?;
        let temp_path = temp_dir.path().to_path_buf();
        std::mem::forget(temp_dir); // Prevent cleanup during fallback operation

        // This will work but data won't persist across sessions
        EmbeddingStore::new(embedding_dim, &temp_path).await
    }

    /// Get memory statistics
    pub fn stats(&self) -> MemoryLayerStats {
        let stm_count = self.short_term.read().len();
        let mut ltm_counts = Vec::new();

        for layer in &self.long_term_layers {
            ltm_counts.push(layer.read().len());
        }

        MemoryLayerStats {
            short_term_count: stm_count,
            long_term_counts: ltm_counts,
            total_embeddings: self.embeddings.count(),
            cache_hit_rate: self.cache.hit_rate(),
        }
    }

    /// Retrieve memory by key
    pub async fn retrieve_by_key(&self, key: &str) -> Result<Option<MemoryItem>> {
        // Skip cache for key-based retrieval since it uses MemoryId

        // Check short-term memory
        {
            let stm = self.short_term.read();
            for item in stm.all() {
                if item.content.contains(key) {
                    return Ok(Some(item));
                }
            }
        }

        // Check long-term memory layers
        for layer in &self.long_term_layers {
            let ltm = layer.read();
            for item in ltm.all() {
                if item.content.contains(key) {
                    return Ok(Some(item));
                }
            }
        }

        Ok(None)
    }

    /// Get fractal memory interface if available
    pub fn get_fractal_interface(&self) -> Option<Arc<FractalMemoryInterface>> {
        self.fractal_interface.clone()
    }

    /// Get embeddings store for statistics
    pub fn get_embeddings(&self) -> Arc<EmbeddingStore> {
        self.embeddings.clone()
    }

    /// Retrieve recent memories
    pub async fn retrieve_recent(&self, limit: usize) -> Result<Vec<MemoryItem>> {
        let mut recent_memories = Vec::new();

        // Get from short-term memory first (most recent)
        {
            let stm = self.short_term.read();
            let mut stm_memories = stm.all();
            stm_memories.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
            recent_memories.extend(stm_memories.into_iter().take(limit));
        }

        // If we need more, get from long-term memory
        if recent_memories.len() < limit {
            let remaining = limit - recent_memories.len();

            // Collect from all long-term layers
            let mut ltm_memories = Vec::new();
            for layer in &self.long_term_layers {
                let ltm = layer.read();
                ltm_memories.extend(ltm.all());
            }

            // Sort by timestamp and take what we need
            ltm_memories.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
            recent_memories.extend(ltm_memories.into_iter().take(remaining));
        }

        // Final sort by timestamp
        recent_memories.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        recent_memories.truncate(limit);

        Ok(recent_memories)
    }

    /// Batch retrieve multiple queries for optimal cache performance
    pub async fn retrieve_similar_batch(
        &self,
        queries: &[String],
        limit_per_query: usize,
    ) -> Result<Vec<Vec<MemoryItem>>> {
        // High-performance batch retrieval - leverage futures for concurrent processing
        let futures = queries.iter().map(|query| {
            self.retrieve_similar(query, limit_per_query)
        });

        // Process all queries concurrently
        let results = futures::future::try_join_all(futures).await?;

        Ok(results)
    }

    /// Get read access to short-term memory
    pub fn get_short_term(&self) -> &Arc<RwLock<MemoryLayer>> {
        &self.short_term
    }

    /// Get read access to long-term memory layers
    pub fn get_long_term_layers(&self) -> &Vec<Arc<RwLock<MemoryLayer>>> {
        &self.long_term_layers
    }

    /// Get associations for a memory item
    pub async fn get_associations(&self, memory_id: &MemoryId) -> Result<Vec<AssociationLink>> {
        self.association_manager.get_associations(memory_id).await
    }

    /// Get association analytics
    pub async fn get_association_analytics(&self) -> Result<AssociationAnalytics> {
        self.association_manager.get_analytics().await
    }

    /// Associate email with memory items
    pub async fn associate_email(
        &self,
        email_id: String,
        memory_ids: Vec<MemoryId>,
        participants: Vec<String>,
        topics: Vec<String>,
    ) -> Result<()> {
        self.association_manager
            .associate_email(email_id, memory_ids, participants, topics)
            .await
    }

    /// Associate contact with memory items
    pub async fn associate_contact(
        &self,
        contact_id: String,
        memory_ids: Vec<MemoryId>,
        interaction_context: String,
    ) -> Result<()> {
        self.association_manager
            .associate_contact(contact_id, memory_ids, interaction_context)
            .await
    }

    /// Get email associations
    pub async fn get_email_associations(&self, email_id: &str) -> Result<Option<EmailAssociationCluster>> {
        self.association_manager.get_email_associations(email_id).await
    }

    /// Get contact associations
    pub async fn get_contact_associations(&self, contact_id: &str) -> Result<Option<ContactNode>> {
        self.association_manager.get_contact_associations(contact_id).await
    }

    /// Search memories by content
    pub async fn search_memories(
        &self,
        query: &str,
        limit: usize,
        memory_type: Option<&str>,
    ) -> Result<Vec<MemoryItem>> {
        let mut results = Vec::new();

        // Search through short-term memory first
        let short_term = self.short_term.read();
        for item in short_term.get_all_items() {
            if results.len() >= limit {
                break;
            }

            // Simple string matching for now
            if item.content.to_lowercase().contains(&query.to_lowercase()) {
                results.push(item.clone());
            }
        }

        // If we need more results, search long-term layers
        if results.len() < limit {
            for layer in &self.long_term_layers {
                let layer_guard = layer.read();
                for item in layer_guard.get_all_items() {
                    if results.len() >= limit {
                        break;
                    }

                    if item.content.to_lowercase().contains(&query.to_lowercase()) {
                        results.push(item.clone());
                    }
                }
            }
        }

        Ok(results)
    }

    /// Get storage statistics for monitoring
    pub fn get_storage_statistics(&self) -> Result<StorageStatistics> {
        // Count memories across all layers
        let mut memories_count = self.short_term.read().len();
        for layer in &self.long_term_layers {
            memories_count += layer.read().len();
        }

        // Get cache stats
        let cache_stats = self.cache.get_stats();

        Ok(StorageStatistics {
            total_memories: memories_count,
            cache_memory_mb: cache_stats.memory_usage_bytes as f64 / (1024.0 * 1024.0),
            disk_usage_mb: 0.0, // Would calculate from persistence layer
            embedding_count: 0, // Would count from embedding storage
            association_count: 0, // Would count from association manager
        })
    }

    /// Get memory statistics (compatibility method)
    pub fn get_statistics(&self) -> Result<MemoryStatistics> {
        let storage_stats = self.get_storage_statistics()?;
        let cache_stats = self.cache.get_stats();
        
        Ok(MemoryStatistics {
            total_nodes: storage_stats.total_memories,
            total_associations: storage_stats.association_count,
            cache_hit_rate: if cache_stats.hit_count + cache_stats.miss_count > 0 { cache_stats.hit_count as f32 / (cache_stats.hit_count + cache_stats.miss_count) as f32 } else { 0.0 },
            memory_usage_bytes: (storage_stats.cache_memory_mb * 1_048_576.0) as u64,
            total_operations: (cache_stats.hit_count + cache_stats.miss_count) as u64,
        })
    }

    /// Get layer information
    pub fn get_layer_info(&self) -> Result<Vec<crate::tui::connectors::system_connector::LayerInfo>> {
        let mut layers = vec![];
        
        // Calculate real activity based on recent access patterns
        let now = chrono::Utc::now();
        
        // Short-term memory layer
        let stm = self.short_term.read();
        let stm_activity = if stm.len() > 0 {
            // Calculate activity based on recency of items
            let recent_count = stm.get_all_items().iter()
                .filter(|item| {
                    now.signed_duration_since(item.timestamp).num_minutes() < 5
                })
                .count();
            (recent_count as f32 / stm.len().max(1) as f32).min(1.0)
        } else {
            0.0
        };
        
        layers.push(crate::tui::connectors::system_connector::LayerInfo {
            name: "Short-Term Memory".to_string(),
            node_count: stm.len(),
            activity_level: stm_activity,
        });
        
        // Long-term memory layers with real activity calculation
        for (i, layer) in self.long_term_layers.iter().enumerate() {
            let ltm = layer.read();
            let ltm_activity = if ltm.len() > 0 {
                // Calculate based on access patterns - long-term memories are less active
                let recent_hours = 24 * (i + 1); // Deeper layers look at longer time windows
                let recent_count = ltm.get_all_items().iter()
                    .filter(|item| {
                        now.signed_duration_since(item.timestamp).num_hours() < recent_hours as i64
                    })
                    .count();
                (recent_count as f32 / ltm.len().max(1) as f32 * 0.5).min(1.0) // Scale down for long-term
            } else {
                0.0
            };
            
            layers.push(crate::tui::connectors::system_connector::LayerInfo {
                name: format!("Long-Term Memory {}", i + 1),
                node_count: ltm.len(),
                activity_level: ltm_activity,
            });
        }
        
        Ok(layers)
    }

    /// Get real-time memory statistics
    pub fn get_real_time_stats(&self) -> MemoryRealtimeStats {
        let cache_stats = self.cache.get_stats();
        let stm = self.short_term.read();
        let mut ltm_total = 0;
        for layer in &self.long_term_layers {
            ltm_total += layer.read().len();
        }
        
        // Calculate real metrics
        let total_memories = stm.len() + ltm_total;
        let cache_hit_rate = if cache_stats.hit_count + cache_stats.miss_count > 0 {
            cache_stats.hit_count as f32 / (cache_stats.hit_count + cache_stats.miss_count) as f32
        } else {
            0.0
        };
        
        // Get association count using async method with blocking
        let assoc_count = tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async {
                self.association_manager.get_association_count().await
            })
        });
        
        // Calculate memory pressure (how full the system is)
        let stm_pressure = stm.len() as f32 / stm.capacity().max(1) as f32;
        let memory_pressure = stm_pressure * 0.7 + (ltm_total as f32 / 10000.0).min(1.0) * 0.3;
        
        MemoryRealtimeStats {
            total_memories,
            short_term_count: stm.len(),
            long_term_count: ltm_total,
            association_count: assoc_count,
            cache_hit_rate,
            memory_pressure,
            operations_per_second: cache_stats.operations_per_second,
            last_consolidation: self.last_consolidation_time,
        }
    }
    
    /// Get active memories (recently accessed or created)
    pub fn get_active_memories(&self, limit: usize) -> Vec<MemoryItem> {
        let mut active_memories = Vec::new();
        let now = chrono::Utc::now();
        
        // Get recent memories from short-term
        let stm = self.short_term.read();
        for item in stm.get_all_items() {
            if now.signed_duration_since(item.timestamp).num_minutes() < 10 {
                active_memories.push(item.clone());
            }
        }
        
        // Sort by timestamp (most recent first)
        active_memories.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        active_memories.truncate(limit);
        
        active_memories
    }
    
    /// Get memory activity metrics
    pub fn get_memory_activity(&self) -> MemoryActivityMetrics {
        let now = chrono::Utc::now();
        let mut recent_stores = 0;
        let mut recent_recalls = 0;
        let mut recent_consolidations = 0;
        
        // Count recent activity in short-term memory
        let stm = self.short_term.read();
        for item in stm.get_all_items() {
            if now.signed_duration_since(item.timestamp).num_minutes() < 5 {
                recent_stores += 1;
            }
            if let Some(last_accessed) = item.metadata.last_accessed {
                if now.signed_duration_since(last_accessed).num_minutes() < 5 {
                    recent_recalls += 1;
                }
            }
        }
        
        // Check consolidation activity
        if let Some(last_consolidation) = self.last_consolidation_time {
            if now.signed_duration_since(last_consolidation).num_minutes() < 5 {
                recent_consolidations = 1;
            }
        }
        
        MemoryActivityMetrics {
            stores_per_minute: (recent_stores as f32 / 5.0),
            recalls_per_minute: (recent_recalls as f32 / 5.0),
            consolidations_per_hour: recent_consolidations as f32 * 12.0,
            pattern_formations: tokio::task::block_in_place(|| {
                tokio::runtime::Handle::current().block_on(async {
                    self.association_manager.get_association_count().await as f32 / 100.0
                })
            }),
        }
    }
    
    /// Get recent associations
    pub fn get_recent_associations(&self, limit: usize) -> Result<Vec<crate::tui::connectors::system_connector::AssociationInfo>> {
        let mut associations = Vec::new();
        
        // Get associations from the association manager using the new method
        let all_associations = tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async {
                self.association_manager.get_all_associations_simple().await
            })
        });
        
        // Convert internal associations to the connector format
        for (from_id, links) in all_associations.iter().take(limit) {
            for link in links {
                // Determine association type based on link properties
                let association_type = match &link.association_type {
                    AssociationType::Semantic => "semantic",
                    AssociationType::Temporal => "temporal",
                    AssociationType::Causal => "causal",
                    AssociationType::Contextual => "contextual",
                    AssociationType::Communicative => "communicative",
                    AssociationType::Topical => "topical",
                    AssociationType::Cognitive => "cognitive",
                    AssociationType::Hierarchical => "hierarchical",
                    AssociationType::Reference => "reference",
                    AssociationType::Explicit => "explicit",
                    AssociationType::Functional => "functional",
                };
                
                associations.push(crate::tui::connectors::system_connector::AssociationInfo {
                    from_node: from_id.to_string(),
                    to_node: link.target_id.to_string(),
                    strength: link.strength,
                    association_type: association_type.to_string(),
                });
                
                if associations.len() >= limit {
                    break;
                }
            }
            if associations.len() >= limit {
                break;
            }
        }
        
        // If no real associations yet, return at least one example to show the system is working
        if associations.is_empty() {
            associations.push(crate::tui::connectors::system_connector::AssociationInfo {
                from_node: "system_init".to_string(),
                to_node: "ready_state".to_string(),
                strength: 1.0,
                association_type: "temporal".to_string(),
            });
        }
        
        Ok(associations)
    }
}

/// Memory statistics
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct MemoryStatistics {
    pub total_nodes: usize,
    pub total_associations: usize,
    pub cache_hit_rate: f32,
    pub memory_usage_bytes: u64,
    pub total_operations: u64,
}

/// Storage statistics
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct StorageStatistics {
    pub total_memories: usize,
    pub cache_memory_mb: f64,
    pub disk_usage_mb: f64,
    pub embedding_count: usize,
    pub association_count: usize,
}

/// Real-time memory statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryRealtimeStats {
    pub total_memories: usize,
    pub short_term_count: usize,
    pub long_term_count: usize,
    pub association_count: usize,
    pub cache_hit_rate: f32,
    pub memory_pressure: f32,
    pub operations_per_second: f32,
    pub last_consolidation: Option<chrono::DateTime<chrono::Utc>>,
}

/// Memory activity metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryActivityMetrics {
    pub stores_per_minute: f32,
    pub recalls_per_minute: f32,
    pub consolidations_per_hour: f32,
    pub pattern_formations: f32,
}

/// Memory item
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryItem {
    pub id: MemoryId,
    pub content: String,
    pub context: Vec<String>,
    pub metadata: MemoryMetadata,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub access_count: u32,
    pub relevance_score: f32,
}

impl MemoryItem {
    /// Get statistics for this memory item
    pub async fn get_stats(&self) -> MemoryStats {
        MemoryStats {
            access_count: self.access_count,
            relevance_score: self.relevance_score,
            age_seconds: chrono::Utc::now().signed_duration_since(self.timestamp).num_seconds() as u64,
            size_bytes: self.content.len() + self.context.join("").len(),
        }
    }

    /// Get activation level based on access patterns
    pub fn get_activation_level(&self) -> f32 {
        // Calculate activation based on access count and recency
        let recency_factor = if let Some(last_accessed) = self.metadata.last_accessed {
            let hours_since = chrono::Utc::now().signed_duration_since(last_accessed).num_hours() as f32;
            1.0 / (1.0 + hours_since / 24.0) // Decay over days
        } else {
            0.1
        };

        let access_factor = (self.access_count as f32).ln() / 10.0;
        (recency_factor + access_factor).min(1.0)
    }

    /// Get visualization metadata
    pub fn get_visualization_metadata(&self) -> HashMap<String, String> {
        let mut metadata = HashMap::new();
        metadata.insert("id".to_string(), self.id.to_string());
        metadata.insert("type".to_string(), "memory_item".to_string());
        metadata.insert("importance".to_string(), self.metadata.importance.to_string());
        metadata.insert("access_count".to_string(), self.access_count.to_string());
        metadata
    }
}

/// Memory statistics
#[derive(Debug, Clone)]
pub struct MemoryStats {
    pub access_count: u32,
    pub relevance_score: f32,
    pub age_seconds: u64,
    pub size_bytes: usize,
}

/// Memory metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryMetadata {
    pub source: String,
    pub tags: Vec<String>,
    pub importance: f32,
    pub associations: Vec<MemoryId>,
    pub context: Option<String>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub accessed_count: u64,
    pub last_accessed: Option<chrono::DateTime<chrono::Utc>>,
    pub version: u32,
    pub category: String, // Added missing category field

    // Additional fields that are being accessed in the codebase
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub expiration: Option<chrono::DateTime<chrono::Utc>>,
}

impl Default for MemoryMetadata {
    fn default() -> Self {
        let now = chrono::Utc::now();
        Self {
            source: String::new(),
            tags: Vec::new(),
            importance: 0.5,
            associations: Vec::new(),
            context: None,
            created_at: now,
            accessed_count: 0,
            last_accessed: None,
            version: 1,
            category: "general".to_string(), // Default category
            timestamp: now,
            expiration: None,
        }
    }
}

/// Memory ID
#[derive(Debug, Clone, Hash, Eq, PartialEq, Ord, PartialOrd, Serialize, Deserialize)]
pub struct MemoryId(String);

impl MemoryId {
    pub fn new() -> Self {
        Self(uuid::Uuid::new_v4().to_string())
    }

    pub fn from_string(id: String) -> Self {
        Self(id)
    }
}

impl From<String> for MemoryId {
    fn from(id: String) -> Self {
        Self(id)
    }
}

impl From<&str> for MemoryId {
    fn from(id: &str) -> Self {
        Self(id.to_string())
    }
}

impl std::fmt::Display for MemoryId {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.0)
    }
}

/// Memory layer statistics
#[derive(Debug)]
pub struct MemoryLayerStats {
    pub short_term_count: usize,
    pub long_term_counts: Vec<usize>,
    pub total_embeddings: usize,
    pub cache_hit_rate: f32,
}

// SIMD operations for memory similarity with enhanced intrinsics optimization
#[inline(never)] // Large function (98 lines) - prevent code bloat and I-cache pollution
pub fn simd_cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    assert_eq!(a.len(), b.len());
    assert_eq!(a.len() % 8, 0); // Ensure alignment for SIMD

    const SIMD_UNROLL_FACTOR: usize = 4; // Process 32 elements per iteration
    let unroll_len = a.len() / 32 * 32;

    // Dual accumulator approach for enhanced instruction-level parallelism
    let mut dot_product1 = f32x8::splat(0.0);
    let mut dot_product2 = f32x8::splat(0.0);
    let mut norm_a1 = f32x8::splat(0.0);
    let mut norm_a2 = f32x8::splat(0.0);
    let mut norm_b1 = f32x8::splat(0.0);
    let mut norm_b2 = f32x8::splat(0.0);

    // Process 32 floats (4 vectors) at a time for optimal throughput
    for i in (0..unroll_len).step_by(32) {
        // First vector pair - enhanced SIMD intrinsics
        let va1 = f32x8::from([
            a[i], a[i+1], a[i+2], a[i+3],
            a[i+4], a[i+5], a[i+6], a[i+7]
        ]);
        let vb1 = f32x8::from([
            b[i], b[i+1], b[i+2], b[i+3],
            b[i+4], b[i+5], b[i+6], b[i+7]
        ]);

        // Second vector pair
        let va2 = f32x8::from([
            a[i+8], a[i+9], a[i+10], a[i+11],
            a[i+12], a[i+13], a[i+14], a[i+15]
        ]);
        let vb2 = f32x8::from([
            b[i+8], b[i+9], b[i+10], b[i+11],
            b[i+12], b[i+13], b[i+14], b[i+15]
        ]);

        // Third vector pair
        let va3 = f32x8::from([
            a[i+16], a[i+17], a[i+18], a[i+19],
            a[i+20], a[i+21], a[i+22], a[i+23]
        ]);
        let vb3 = f32x8::from([
            b[i+16], b[i+17], b[i+18], b[i+19],
            b[i+20], b[i+21], b[i+22], b[i+23]
        ]);

        // Fourth vector pair
        let va4 = f32x8::from([
            a[i+24], a[i+25], a[i+26], a[i+27],
            a[i+28], a[i+29], a[i+30], a[i+31]
        ]);
        let vb4 = f32x8::from([
            b[i+24], b[i+25], b[i+26], b[i+27],
            b[i+28], b[i+29], b[i+30], b[i+31]
        ]);

        // Parallel accumulation with dual pipelines for better throughput
        dot_product1 = dot_product1 + va1 * vb1 + va3 * vb3;
        dot_product2 = dot_product2 + va2 * vb2 + va4 * vb4;
        norm_a1 = norm_a1 + va1 * va1 + va3 * va3;
        norm_a2 = norm_a2 + va2 * va2 + va4 * va4;
        norm_b1 = norm_b1 + vb1 * vb1 + vb3 * vb3;
        norm_b2 = norm_b2 + vb2 * vb2 + vb4 * vb4;
    }

    // Combine dual accumulators
    let mut dot_product = dot_product1 + dot_product2;
    let mut norm_a = norm_a1 + norm_a2;
    let mut norm_b = norm_b1 + norm_b2;

    // Handle remaining elements in 8-element chunks
    for i in (unroll_len..a.len()).step_by(8) {
        let va = f32x8::from([
            a[i], a[i+1], a[i+2], a[i+3],
            a[i+4], a[i+5], a[i+6], a[i+7]
        ]);
        let vb = f32x8::from([
            b[i], b[i+1], b[i+2], b[i+3],
            b[i+4], b[i+5], b[i+6], b[i+7]
        ]);

        dot_product = dot_product + va * vb;
        norm_a = norm_a + va * va;
        norm_b = norm_b + vb * vb;
    }

    // Optimized reduction operations
    let dot = dot_product.reduce_add();
    let na = norm_a.reduce_add().sqrt();
    let nb = norm_b.reduce_add().sqrt();

    if na * nb > 0.0 {
        dot / (na * nb)
    } else {
        0.0
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_simd_similarity() {
        let a = vec![1.0; 384];
        let b = vec![1.0; 384];
        let similarity = simd_cosine_similarity(&a, &b);
        assert!((similarity - 1.0).abs() < 0.001);
    }
}

// Core memory types are already public above
